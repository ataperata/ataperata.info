// Dynamic Python Code Execution Demos for Ata AI

// AI-powered responses for different demo types
const demoResponses = {
    ml: [
        "ğŸ¤– Neural network created successfully!\nğŸ“Š Model architecture: 128 â†’ 10 neurons\nâš¡ Optimizer: Adam\nğŸ¯ Ready for training...\n\nğŸ”¥ Training initiated...\nEpoch 1/10 - Loss: 2.3456 - Accuracy: 0.1234\nEpoch 2/10 - Loss: 1.8923 - Accuracy: 0.3456\nEpoch 3/10 - Loss: 1.4567 - Accuracy: 0.5678\nEpoch 4/10 - Loss: 1.1234 - Accuracy: 0.7123\nEpoch 5/10 - Loss: 0.8901 - Accuracy: 0.8345\nEpoch 6/10 - Loss: 0.6789 - Accuracy: 0.8967\nEpoch 7/10 - Loss: 0.5234 - Accuracy: 0.9234\nEpoch 8/10 - Loss: 0.4123 - Accuracy: 0.9456\nEpoch 9/10 - Loss: 0.3456 - Accuracy: 0.9678\nEpoch 10/10 - Loss: 0.2987 - Accuracy: 0.9789\n\nâœ… Training completed!\nğŸ‰ Final accuracy: 97.89%\nğŸ“ˆ Model saved to: ata_neural_network.h5",
        
        "ğŸ§  Advanced Deep Learning Model Training\n================================\n\nğŸ”„ Initializing TensorFlow environment...\nâœ… GPU detected: NVIDIA Tesla V100\nğŸš€ CUDA acceleration enabled\n\nğŸ“Š Dataset loaded: 60,000 training samples\nğŸ¯ Target classes: 10 categories\n\nğŸ—ï¸ Building neural architecture:\n   Layer 1: Dense(128) + ReLU + Dropout(0.2)\n   Layer 2: Dense(64) + ReLU + Dropout(0.3)\n   Layer 3: Dense(32) + ReLU\n   Output: Dense(10) + Softmax\n\nâš¡ Compiling with Adam optimizer...\nğŸ“ˆ Learning rate: 0.001\nğŸ¯ Loss function: Categorical Crossentropy\n\nğŸ”¥ Training in progress...\n[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% - ETA: 0s\n\nğŸŠ Training Results:\n   â€¢ Final Loss: 0.0234\n   â€¢ Validation Accuracy: 98.76%\n   â€¢ Training Time: 2m 34s\n   â€¢ Parameters: 125,482\n\nğŸ† Model performance exceeds expectations!"
    ],
    
    nlp: [
        "ğŸ”¤ NLP Sentiment Analysis Results\n" +
        "=".repeat(40) + "\n\n" +
        "Text: I absolutely love this AI technology!\n" +
        "Sentiment: ğŸ˜Š Positive (Score: 0.89)\n" +
        "Confidence: 94.2%\n" +
        "Key emotions: joy, excitement, admiration\n" +
        "-".repeat(50) + "\n\n" +
        "Text: This is terrible and disappointing.\n" +
        "Sentiment: ğŸ˜¢ Negative (Score: -0.76)\n" +
        "Confidence: 91.8%\n" +
        "Key emotions: disappointment, frustration\n" +
        "-".repeat(50) + "\n\n" +
        "Text: The weather is okay today.\n" +
        "Sentiment: ğŸ˜ Neutral (Score: 0.02)\n" +
        "Confidence: 87.3%\n" +
        "Key emotions: neutrality, mild positivity\n\n" +
        "ğŸ“Š Analysis Summary:\n" +
        "   â€¢ Processed: 3 texts\n" +
        "   â€¢ Average confidence: 91.1%\n" +
        "   â€¢ Processing time: 0.12s\n" +
        "   â€¢ Language detected: English\n\n" +
        "ğŸ¯ Advanced NLP features activated:\n" +
        "   âœ… Emotion recognition\n" +
        "   âœ… Context analysis\n" +
        "   âœ… Sarcasm detection\n" +
        "   âœ… Multi-language support",
        
        "ğŸ¤– Advanced Text Processing Pipeline\n" +
        "=" .repeat(45) + "\n\n" +
        "ğŸ” Analyzing text corpus...\n" +
        "ğŸ“š Documents processed: 1,247\n" +
        "ğŸ”¤ Total tokens: 284,593\n" +
        "ğŸ·ï¸ Named entities: 3,842\n\n" +
        "ğŸ§  NLP Tasks Completed:\n" +
        "   âœ… Tokenization & Lemmatization\n" +
        "   âœ… POS Tagging (98.7% accuracy)\n" +
        "   âœ… Named Entity Recognition\n" +
        "   âœ… Sentiment Classification\n" +
        "   âœ… Topic Modeling (LDA)\n" +
        "   âœ… Text Summarization\n\n" +
        "ğŸ“Š Key Insights:\n" +
        "   â€¢ Most common sentiment: Positive (67%)\n" +
        "   â€¢ Top topics: Technology, Innovation, AI\n" +
        "   â€¢ Reading level: College (Grade 14)\n" +
        "   â€¢ Keyword density: Optimal\n\n" +
        "ğŸŒŸ Text Quality Score: 94/100\n" +
        "âš¡ Processing speed: 1,247 docs/sec"
    ],
    
    vision: [
        "ğŸ” Computer Vision Object Detection\n" +
        "=" .repeat(40) + "\n\n" +
        "ğŸ“¸ Processing image: sample_image.jpg\n" +
        "ğŸ–¼ï¸ Resolution: 1920x1080 pixels\n" +
        "ğŸ¯ Detection algorithm: YOLO v8\n\n" +
        "ğŸ¤– Objects Detected:\n" +
        "-".repeat(30) + "\n\n" +
        "âœ… PERSON\n" +
        "   Confidence: 96.3%\n" +
        "   Bounding Box: [100, 50, 200, 300]\n" +
        "   Attributes: adult, standing, frontal_view\n" +
        "   Pose: confident, arms_crossed\n\n" +
        "âœ… CAR\n" +
        "   Confidence: 89.7%\n" +
        "   Bounding Box: [300, 150, 500, 250]\n" +
        "   Type: sedan, blue, modern\n" +
        "   License plate: partially_visible\n\n" +
        "âœ… DOG\n" +
        "   Confidence: 92.1%\n" +
        "   Bounding Box: [150, 200, 250, 350]\n" +
        "   Breed: Golden Retriever (87% confidence)\n" +
        "   Activity: sitting, alert\n\n" +
        "ğŸ“Š Detection Summary:\n" +
        "   â€¢ Total objects: 3\n" +
        "   â€¢ Processing time: 0.045s\n" +
        "   â€¢ Average confidence: 92.7%\n" +
        "   â€¢ GPU acceleration: ON\n\n" +
        "ğŸ¯ Advanced features activated:\n" +
        "   âœ… Facial recognition\n" +
        "   âœ… Emotion detection\n" +
        "   âœ… Age estimation\n" +
        "   âœ… Real-time tracking",
        
        "ğŸ¥ Real-time Video Analysis Pipeline\n" +
        "=" .repeat(42) + "\n\n" +
        "ğŸ“¹ Input: HD video stream (30 FPS)\n" +
        "ğŸ–¥ï¸ Processing: Edge AI accelerator\n" +
        "âš¡ Latency: 16ms per frame\n\n" +
        "ğŸ” Multi-object Tracking Results:\n" +
        "-".repeat(35) + "\n\n" +
        "ğŸ‘¥ People detected: 5\n" +
        "   â€¢ ID_001: Walking (confidence: 94%)\n" +
        "   â€¢ ID_002: Running (confidence: 91%)\n" +
        "   â€¢ ID_003: Standing (confidence: 97%)\n" +
        "   â€¢ ID_004: Sitting (confidence: 89%)\n" +
        "   â€¢ ID_005: Cycling (confidence: 93%)\n\n" +
        "ğŸš— Vehicles tracked: 3\n" +
        "   â€¢ Car_A: Moving left (68 km/h)\n" +
        "   â€¢ Truck_B: Stationary\n" +
        "   â€¢ Bike_C: Moving right (25 km/h)\n\n" +
        "ğŸ·ï¸ Scene Understanding:\n" +
        "   â€¢ Location: Urban street\n" +
        "   â€¢ Weather: Sunny, clear\n" +
        "   â€¢ Time of day: Afternoon\n" +
        "   â€¢ Traffic density: Moderate\n\n" +
        "ğŸ¯ AI Insights:\n" +
        "   â€¢ Anomaly detection: None\n" +
        "   â€¢ Safety score: 8.7/10\n" +
        "   â€¢ Crowd density: Low"
    ],
    
    data: [
        "ğŸ¤– AI Model Performance Analysis\n" +
        "=" .repeat(40) + "\n\n" +
        "ğŸ“Š Dataset Shape: (30, 4)\n" +
        "ğŸ“ˆ Average Accuracy: 0.946\n" +
        "âš¡ Avg Inference Time: 51.2ms\n" +
        "ğŸ“‰ Final Training Loss: 0.0847\n\n" +
        "ğŸ” Top 5 Performance Days:\n" +
        "-".repeat(35) + "\n" +
        "2024-01-15    0.979\n" +
        "2024-01-08    0.971\n" +
        "2024-01-22    0.968\n" +
        "2024-01-29    0.965\n" +
        "2024-01-01    0.962\n\n" +
        "ğŸ“Š Accuracy Statistics:\n" +
        "   Min: 0.891\n" +
        "   Max: 0.979\n" +
        "   Std: 0.023\n" +
        "   Median: 0.948\n" +
        "   Q1: 0.932\n" +
        "   Q3: 0.961\n\n" +
        "ğŸ¯ Performance Insights:\n" +
        "   â€¢ Model stability: Excellent\n" +
        "   â€¢ Overfitting risk: Low\n" +
        "   â€¢ Generalization: Strong\n" +
        "   â€¢ Recommended action: Deploy to production\n\n" +
        "ğŸ“ˆ Trend Analysis:\n" +
        "   â€¢ 30-day improvement: +5.7%\n" +
        "   â€¢ Best performing time: Afternoon\n" +
        "   â€¢ Consistency score: 94/100",
        
        "ğŸ“Š Advanced Data Science Pipeline\n" +
        "=" .repeat(42) + "\n\n" +
        "ğŸ”„ Data Processing Stages:\n" +
        "   âœ… Data ingestion (1.2M records)\n" +
        "   âœ… Quality assessment (99.7% valid)\n" +
        "   âœ… Feature engineering (847 features)\n" +
        "   âœ… Dimensionality reduction (PCA)\n" +
        "   âœ… Train/test split (80/20)\n\n" +
        "ğŸ¤– ML Model Comparison:\n" +
        "-".repeat(30) + "\n" +
        "Random Forest:     94.2% Â± 0.8%\n" +
        "XGBoost:          96.7% Â± 0.5%\n" +
        "Neural Network:   97.8% Â± 0.3%\n" +
        "Ensemble Model:   98.4% Â± 0.2%\n\n" +
        "ğŸ† Best Model: Ensemble\n" +
        "   â€¢ Cross-validation: 98.4%\n" +
        "   â€¢ Test accuracy: 98.1%\n" +
        "   â€¢ F1-score: 0.981\n" +
        "   â€¢ AUC-ROC: 0.994\n\n" +
        "ğŸ“ˆ Feature Importance:\n" +
        "   1. neural_activation (0.234)\n" +
        "   2. learning_rate (0.189)\n" +
        "   3. batch_size (0.156)\n" +
        "   4. dropout_ratio (0.134)\n" +
        "   5. optimizer_type (0.112)\n\n" +
        "ğŸ¯ Business Impact:\n" +
        "   â€¢ Revenue increase: +23%\n" +
        "   â€¢ Cost reduction: -18%\n" +
        "   â€¢ Customer satisfaction: +31%"
    ]
};

// Typing animation function
function typeText(element, text, speed = 30) {
    element.textContent = '';
    let i = 0;
    
    function typeChar() {
        if (i < text.length) {
            element.textContent += text.charAt(i);
            i++;
            setTimeout(typeChar, speed);
        }
    }
    
    typeChar();
}

// Add syntax highlighting to code blocks
function highlightCode() {
    if (typeof Prism !== 'undefined') {
        Prism.highlightAll();
    }
}

// Simulate realistic delays and processing
function simulateProcessing(outputElement, finalText, processingSteps) {
    const steps = [
        "ğŸ”„ Initializing AI engine...",
        "ğŸ“Š Loading datasets...",
        "ğŸ§  Activating neural networks...",
        "âš¡ GPU acceleration enabled...",
        "ğŸ¯ Processing algorithms...",
        "âœ¨ Generating results..."
    ];
    
    let stepIndex = 0;
    outputElement.textContent = steps[0];
    
    const processInterval = setInterval(() => {
        stepIndex++;
        if (stepIndex < steps.length) {
            outputElement.textContent = steps[stepIndex];
        } else {
            clearInterval(processInterval);
            setTimeout(() => {
                typeText(outputElement, finalText, 15);
            }, 500);
        }
    }, 800);
}

// ML Demo Function
function runMLDemo() {
    const outputElement = document.getElementById('ml-output').querySelector('.output-content');
    const runBtn = document.querySelector('.demo-card .run-btn');
    
    // Disable button and show loading
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Running...';
    runBtn.disabled = true;
    
    // Add some visual effects
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-cyber-glow');
    
    // Get random response
    const responses = demoResponses.ml;
    const randomResponse = responses[Math.floor(Math.random() * responses.length)];
    
    // Simulate processing
    simulateProcessing(outputElement, randomResponse);
    
    // Reset button after completion
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Run';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-cyber-glow');
    }, 8000);
}

// NLP Demo Function
function runNLPDemo() {
    const outputElement = document.getElementById('nlp-output').querySelector('.output-content');
    const runBtn = document.querySelectorAll('.run-btn')[1];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Analyzing...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-hologram');
    
    const responses = demoResponses.nlp;
    const randomResponse = responses[Math.floor(Math.random() * responses.length)];
    
    simulateProcessing(outputElement, randomResponse);
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Run';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-hologram');
    }, 7500);
}

// Computer Vision Demo Function
function runVisionDemo() {
    const outputElement = document.getElementById('vision-output').querySelector('.output-content');
    const runBtn = document.querySelectorAll('.run-btn')[2];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Detecting...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-neural-pulse');
    
    const responses = demoResponses.vision;
    const randomResponse = responses[Math.floor(Math.random() * responses.length)];
    
    simulateProcessing(outputElement, randomResponse);
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Run';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-neural-pulse');
    }, 9000);
}

// Data Analysis Demo Function
function runDataDemo() {
    const outputElement = document.getElementById('data-output').querySelector('.output-content');
    const runBtn = document.querySelectorAll('.run-btn')[3];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Computing...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-code-scan');
    
    const responses = demoResponses.data;
    const randomResponse = responses[Math.floor(Math.random() * responses.length)];
    
    simulateProcessing(outputElement, randomResponse);
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Run';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-code-scan');
    }, 8500);
}

// Auto-run demos periodically for demo effect
function startAutoDemo() {
    const demos = [runMLDemo, runNLPDemo, runVisionDemo, runDataDemo];
    let currentDemo = 0;
    
    setInterval(() => {
        // Only auto-run if not currently running
        const runBtns = document.querySelectorAll('.run-btn');
        const anyRunning = Array.from(runBtns).some(btn => btn.disabled);
        
        if (!anyRunning && Math.random() > 0.7) { // 30% chance every interval
            demos[currentDemo]();
            currentDemo = (currentDemo + 1) % demos.length;
        }
    }, 15000); // Every 15 seconds
}

// Progress bar animation for code execution
function showProgress(element, duration = 3000) {
    const progressBar = document.createElement('div');
    progressBar.className = 'progress-bar';
    progressBar.innerHTML = '<div class="progress-fill"></div>';
    
    const progressFill = progressBar.querySelector('.progress-fill');
    element.appendChild(progressBar);
    
    // Animate progress
    progressFill.style.width = '0%';
    progressFill.style.transition = `width ${duration}ms ease-out`;
    
    setTimeout(() => {
        progressFill.style.width = '100%';
    }, 100);
    
    // Remove progress bar after completion
    setTimeout(() => {
        progressBar.remove();
    }, duration + 500);
}

// Add code execution sound effects (optional)
function playExecutionSound() {
    // Create audio context for futuristic beeps
    if (typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined') {
        const AudioContextClass = AudioContext || webkitAudioContext;
        const audioContext = new AudioContextClass();
        
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();
        
        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        oscillator.frequency.setValueAtTime(800, audioContext.currentTime);
        oscillator.frequency.exponentialRampToValueAtTime(400, audioContext.currentTime + 0.1);
        
        gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
        gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.1);
        
        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + 0.1);
    }
}

// Initialize demos when page loads
document.addEventListener('DOMContentLoaded', function() {
    // Highlight existing code
    highlightCode();
    
    // Start auto demo after page load
    setTimeout(startAutoDemo, 5000);
    
    // Add CSS for progress bar
    const style = document.createElement('style');
    style.textContent = `
        .progress-bar {
            width: 100%;
            height: 4px;
            background: rgba(0, 212, 255, 0.2);
            border-radius: 2px;
            margin: 10px 0;
            overflow: hidden;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #00d4ff, #ff6b9d);
            border-radius: 2px;
            transition: width 3s ease-out;
        }
    `;
    document.head.appendChild(style);
    
    // Add hover effects to demo cards
    const demoCards = document.querySelectorAll('.demo-card');
    demoCards.forEach(card => {
        card.addEventListener('mouseenter', function() {
            this.style.transform = 'translateY(-5px) scale(1.02)';
            this.style.transition = 'all 0.3s ease';
        });
        
        card.addEventListener('mouseleave', function() {
            this.style.transform = 'translateY(0) scale(1)';
        });
    });
});

// Neural Network Visualization Demo
function runNeuralVizDemo() {
    const outputElement = document.getElementById('neural-viz-output').querySelector('.output-content');
    const canvas = document.getElementById('neural-canvas');
    const ctx = canvas ? canvas.getContext('2d') : null;
    const runBtn = document.querySelectorAll('.run-btn')[4];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Visualizing...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-neural-pulse');
    
    // Simulate neural network visualization
    const response = `ğŸ§  Neural Network Live Inference
${'='.repeat(50)}

âš¡ Frame 1/10:
   Input shape: (1, 256)
   Layer 1 activation: 0.3247
   Layer 2 activation: 0.5891
   Layer 3 activation: 0.4123
   Prediction confidence: 0.8934
${'â”€'.repeat(40)}

âš¡ Frame 2/10:
   Input shape: (1, 256)
   Layer 1 activation: 0.4562
   Layer 2 activation: 0.3789
   Layer 3 activation: 0.6234
   Prediction confidence: 0.9187
${'â”€'.repeat(40)}

âš¡ Frame 3/10:
   Input shape: (1, 256)
   Layer 1 activation: 0.2987
   Layer 2 activation: 0.7123
   Layer 3 activation: 0.5456
   Prediction confidence: 0.8756

ğŸš€ Neural network inference completed!
ğŸ“Š Average activation: 0.4892
ğŸ¯ Processing speed: 1,247 fps
âš¡ Memory usage: 2.3 GB`;
    
    simulateProcessing(outputElement, response);
    
    // Animate neural network visualization
    if (ctx) {
        animateNeuralNetwork(ctx);
    }
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Visualize';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-neural-pulse');
    }, 9500);
}

// Quantum Computing Demo
function runQuantumDemo() {
    const outputElement = document.getElementById('quantum-output').querySelector('.output-content');
    const runBtn = document.querySelectorAll('.run-btn')[5];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Computing...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-quantum');
    
    const response = `ğŸŒŒ Quantum AI Processing Initiated
${'='.repeat(45)}

âš›ï¸  Quantum Circuit Created:
   Qubits: 8
   Gates: Hadamard, CNOT, RY, RZ
   Depth: 12

ğŸ”¬ Quantum State Evolution:
   Step 1: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©, P = 0.3456
   Step 2: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©, P = 0.7891
   Step 3: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©, P = 0.5234
   Step 4: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©, P = 0.9123
   Step 5: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©, P = 0.6789

ğŸ“Š Measurement Results: [1 0 1 1 0 1 0 1]
ğŸ¯ Quantum Advantage: 0.625
âš¡ Quantum Supremacy: Achieved
ğŸŒŸ Entanglement Fidelity: 98.7%

âœ¨ Quantum computation completed with 8 qubits!`;
    
    simulateProcessing(outputElement, response);
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Execute';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-quantum');
    }, 10000);
}

// Robotics Control Demo
function runRoboticsDemo() {
    const outputElement = document.getElementById('robotics-output').querySelector('.output-content');
    const runBtn = document.querySelectorAll('.run-btn')[6];
    
    runBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Deploying...';
    runBtn.disabled = true;
    
    const demoCard = runBtn.closest('.demo-card');
    demoCard.classList.add('animate-ai-thinking');
    
    const response = `ğŸ¤– Autonomous Robot Control System Online
${'='.repeat(50)}

ğŸ¯ Mission: Navigate to multiple waypoints
   Target waypoints: 4
   AI Systems: ['navigation_nn', 'object_detection', 'path_planning', 'decision_making']

ğŸš€ Navigating to waypoint 1: (10, 5)
   ğŸ“¡ LIDAR: Nearest obstacle at 3.45m
   ğŸ“· Camera: 2 objects detected
   ğŸ§  AI Decision: Path clear, proceeding
   â¡ï¸  Moving towards target...
   ğŸ“ Distance to target: 11.2m

ğŸš€ Navigating to waypoint 2: (15, 10)
   ğŸ“¡ LIDAR: Nearest obstacle at 1.23m
   ğŸ“· Camera: 4 objects detected
   ğŸ§  AI Decision: Obstacle avoidance activated
   âš¡ Executing evasive maneuver...
   ğŸ“ Distance to target: 7.8m

ğŸš€ Navigating to waypoint 3: (20, 8)
   ğŸ“¡ LIDAR: Nearest obstacle at 5.67m
   ğŸ“· Camera: 1 objects detected
   ğŸ§  AI Decision: Path clear, proceeding
   â¡ï¸  Moving towards target...
   ğŸ“ Distance to target: 9.1m

ğŸš€ Navigating to waypoint 4: (25, 15)
   ğŸ“¡ LIDAR: Nearest obstacle at 2.89m
   ğŸ“· Camera: 3 objects detected
   ğŸ§  AI Decision: Path clear, proceeding
   â¡ï¸  Moving towards target...
   ğŸ“ Distance to target: 12.3m

âœ… Mission completed!
   Obstacles navigated: 1
   Final position: (25, 15)
   ğŸ† Success rate: 100%
   ğŸ¯ Navigation accuracy: 99.7%
   âš¡ Mission time: 4m 23s`;
    
    simulateProcessing(outputElement, response);
    
    setTimeout(() => {
        runBtn.innerHTML = '<i class="fas fa-play"></i> Deploy';
        runBtn.disabled = false;
        demoCard.classList.remove('animate-ai-thinking');
    }, 11000);
}

// Neural network visualization animation
function animateNeuralNetwork(ctx) {
    const width = ctx.canvas.width;
    const height = ctx.canvas.height;
    let frame = 0;
    
    function draw() {
        // Clear canvas
        ctx.fillStyle = 'rgba(10, 10, 10, 0.1)';
        ctx.fillRect(0, 0, width, height);
        
        // Draw neural network nodes
        const layers = [4, 6, 4, 2];
        const layerSpacing = width / (layers.length + 1);
        
        layers.forEach((nodeCount, layerIndex) => {
            const x = layerSpacing * (layerIndex + 1);
            const nodeSpacing = height / (nodeCount + 1);
            
            for (let i = 0; i < nodeCount; i++) {
                const y = nodeSpacing * (i + 1);
                
                // Animate node activity
                const activity = Math.sin(frame * 0.1 + layerIndex + i) * 0.5 + 0.5;
                const radius = 8 + activity * 4;
                
                // Draw node
                ctx.beginPath();
                ctx.arc(x, y, radius, 0, 2 * Math.PI);
                ctx.fillStyle = `rgba(0, 212, 255, ${0.7 + activity * 0.3})`;
                ctx.fill();
                
                // Draw connections to next layer
                if (layerIndex < layers.length - 1) {
                    const nextLayerX = layerSpacing * (layerIndex + 2);
                    const nextNodeCount = layers[layerIndex + 1];
                    const nextNodeSpacing = height / (nextNodeCount + 1);
                    
                    for (let j = 0; j < nextNodeCount; j++) {
                        const nextY = nextNodeSpacing * (j + 1);
                        
                        ctx.beginPath();
                        ctx.moveTo(x, y);
                        ctx.lineTo(nextLayerX, nextY);
                        ctx.strokeStyle = `rgba(255, 107, 157, ${activity * 0.3})`;
                        ctx.lineWidth = 1 + activity * 2;
                        ctx.stroke();
                    }
                }
            }
        });
        
        frame++;
        if (frame < 200) {
            requestAnimationFrame(draw);
        }
    }
    
    draw();
}

// Export functions for global access
window.runMLDemo = runMLDemo;
window.runNLPDemo = runNLPDemo;
window.runVisionDemo = runVisionDemo;
window.runDataDemo = runDataDemo;
window.runNeuralVizDemo = runNeuralVizDemo;
window.runQuantumDemo = runQuantumDemo;
window.runRoboticsDemo = runRoboticsDemo;